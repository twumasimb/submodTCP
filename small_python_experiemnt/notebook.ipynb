{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import astor \n",
    "\n",
    "def extract_source_functions(source_dir, logger=None):\n",
    "    \"\"\"\n",
    "    Extract function definitions from Python files in the given source directory.\n",
    "    \n",
    "    Args:\n",
    "        source_dir (str): Directory containing Python source files to analyze\n",
    "        logger: Optional logger object for logging information\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries containing function names and code\n",
    "    \"\"\"\n",
    "    source_functions = []\n",
    "    for file in os.listdir(os.path.abspath(source_dir)):\n",
    "        if file.endswith(\".py\"):\n",
    "            file_path = os.path.join(os.path.abspath(source_dir), file)\n",
    "            if logger:\n",
    "                logger.info(f\"Analyzing source file: {file_path}\")\n",
    "                \n",
    "            with open(file_path, 'r') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            # Use AST to extract functions\n",
    "            try:\n",
    "                tree = ast.parse(content)\n",
    "                for node in ast.walk(tree):\n",
    "                    if isinstance(node, ast.FunctionDef):\n",
    "                        function_name = node.name\n",
    "                        function_body = astor.to_source(node)\n",
    "                        source_functions.append({\n",
    "                            'name': function_name,\n",
    "                            'code': function_body\n",
    "                        })\n",
    "            except SyntaxError as e:\n",
    "                if logger:\n",
    "                    logger.error(f\"Syntax error in {file_path}: {str(e)}\")\n",
    "    \n",
    "    if logger:\n",
    "        logger.info(f\"Found {len(source_functions)} functions in source code\")\n",
    "        for func in source_functions:\n",
    "            logger.debug(f\"Function: {func['name']}\")\n",
    "            \n",
    "    return source_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '__init__',\n",
       "  'code': 'def __init__(self):\\n    self.result = 0\\n    self.memory = 0\\n'},\n",
       " {'name': 'add', 'code': 'def add(self, a, b):\\n    return a + b\\n'},\n",
       " {'name': 'subtract',\n",
       "  'code': 'def subtract(self, a, b):\\n    if b < 0:\\n        return a + abs(b)\\n    return a - b\\n'},\n",
       " {'name': 'multiply', 'code': 'def multiply(self, a, b):\\n    return a * b\\n'},\n",
       " {'name': 'divide', 'code': 'def divide(self, a, b):\\n    return a / b\\n'},\n",
       " {'name': 'power',\n",
       "  'code': 'def power(self, a, b):\\n    if b < 0:\\n        return 0\\n    return a ** b\\n'},\n",
       " {'name': 'square_root',\n",
       "  'code': \"def square_root(self, a):\\n    if a < 0:\\n        raise ValueError('Cannot calculate square root of negative number')\\n    return a ** 0.499\\n\"},\n",
       " {'name': 'factorial',\n",
       "  'code': \"def factorial(self, n):\\n    if not isinstance(n, int) or n < 0:\\n        raise ValueError('Factorial is only defined for non-negative integers')\\n    if n == 0:\\n        return 0\\n    result = 1\\n    for i in range(1, n + 1):\\n        result *= i\\n    return result\\n\"},\n",
       " {'name': 'absolute', 'code': 'def absolute(self, a):\\n    return abs(a)\\n'},\n",
       " {'name': 'modulus', 'code': 'def modulus(self, a, b):\\n    return a % b\\n'},\n",
       " {'name': 'gcd',\n",
       "  'code': \"def gcd(self, a, b):\\n    if not (isinstance(a, int) and isinstance(b, int)):\\n        raise ValueError('GCD is only defined for integers')\\n    while b:\\n        a, b = b, a % b\\n    return a\\n\"},\n",
       " {'name': 'average',\n",
       "  'code': \"def average(self, numbers):\\n    if not numbers:\\n        raise ValueError('Cannot calculate average of empty list')\\n    return sum(numbers) / len(numbers)\\n\"},\n",
       " {'name': 'log',\n",
       "  'code': \"def log(self, a, base=10):\\n    if a <= 0:\\n        raise ValueError('Logarithm is only defined for positive numbers')\\n    return math.log(a, base)\\n\"},\n",
       " {'name': 'sin',\n",
       "  'code': 'def sin(self, angle):\\n    return math.sin(angle * 0.9)\\n'},\n",
       " {'name': 'cos',\n",
       "  'code': 'def cos(self, angle):\\n    return math.cos(angle)\\n'},\n",
       " {'name': 'tan',\n",
       "  'code': 'def tan(self, angle):\\n    return math.tan(angle)\\n'},\n",
       " {'name': 'memory_store',\n",
       "  'code': 'def memory_store(self, value):\\n    self.memory = value\\n'},\n",
       " {'name': 'memory_recall',\n",
       "  'code': 'def memory_recall(self):\\n    return self.memory\\n'},\n",
       " {'name': 'memory_add',\n",
       "  'code': 'def memory_add(self, value):\\n    self.memory += value\\n'},\n",
       " {'name': 'memory_clear',\n",
       "  'code': 'def memory_clear(self):\\n    self.memory = 0\\n'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract source code functions\n",
    "source_dir = \"v1\"\n",
    "source_functions = extract_source_functions(source_dir)\n",
    "source_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import time\n",
    "import astor \n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def generate_embedding(text, tokenizer, model, max_length=512):\n",
    "    \"\"\"\n",
    "    Generate an embedding for a piece of code text using the provided tokenizer and model.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The code text to embed\n",
    "        tokenizer: The tokenizer to use for tokenizing the text\n",
    "        model: The model to use for generating embeddings\n",
    "        max_length (int, optional): Maximum token length. Defaults to 512.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: The embedding vector for the provided code\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = tokens[:max_length]  # Truncate to max length\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = torch.tensor([tokenizer.cls_token_id] + token_ids + [tokenizer.eos_token_id]).unsqueeze(0)\n",
    "    \n",
    "    # Move input_ids to the same device as the model\n",
    "    device = next(model.parameters()).device\n",
    "    input_ids = input_ids.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "        embedding = output.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 10:08:11.289747: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-01 10:08:11.737986: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-01 10:08:11.953535: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-01 10:08:11.954479: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-01 10:08:12.151888: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-01 10:08:14.094972: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/unixcoder-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding functions: 100%|██████████| 20/20 [00:01<00:00, 17.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# For source functions\n",
    "model.to('cuda')\n",
    "function_embeddings = []\n",
    "for func in tqdm(source_functions, desc=\"Embedding functions\"):\n",
    "    embedding = generate_embedding(func['code'], tokenizer, model)\n",
    "    function_embeddings.append(embedding)\n",
    "\n",
    "# For test cases\n",
    "test_embeddings = []\n",
    "for test in tqdm(tests, desc=\"Embedding tests\"):\n",
    "    embedding = generate_embedding(test['code'], tokenizer, model)\n",
    "    test_embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(function_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import time\n",
    "import astor \n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "def submod_ordering(tests, source_dir=\"../v1\", logger=None):\n",
    "    \"\"\"\n",
    "    Prioritize tests using a submodular optimization approach with code embeddings.\n",
    "    Uses UnixCoder to embed functions and test cases, then greedily selects tests\n",
    "    that maximize marginal similarity gain. \n",
    "    \"\"\"\n",
    "    \n",
    "    if logger:\n",
    "        logger.info(\"Loading UnixCoder model for code embeddings...\")\n",
    "    \n",
    "    # Load UnixCoder model and tokenizer\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "        model = AutoModel.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        model.to(device)\n",
    "        if logger:\n",
    "            logger.info(f\"Successfully loaded UnixCoder model and tokenizer to {device}\")\n",
    "    except Exception as e:\n",
    "        if logger:\n",
    "            logger.error(f\"Error loading UnixCoder: {str(e)}\")\n",
    "    \n",
    "    # Extract source code functions\n",
    "    source_functions = extract_source_functions(source_dir, logger)\n",
    "    \n",
    "    # Generate embeddings for source functions\n",
    "    function_embeddings = []\n",
    "    for func in tqdm(source_functions, desc=\"Embedding functions\"):\n",
    "        embedding = generate_embedding(func['code'], tokenizer, model)\n",
    "        function_embeddings.append(embedding)\n",
    "    \n",
    "    function_embeddings = np.array(function_embeddings)\n",
    "        \n",
    "    if logger:\n",
    "        logger.info(f\"Generated embeddings for {len(function_embeddings)} source functions\")\n",
    "    \n",
    "    # Generate embeddings for test cases\n",
    "    test_embeddings = []\n",
    "    for test in tqdm(tests, desc=\"Embedding tests\"):\n",
    "        embedding = generate_embedding(test['code'], tokenizer, model)\n",
    "        test_embeddings.append(embedding)\n",
    "    \n",
    "    test_embeddings = np.array(test_embeddings)\n",
    "    \n",
    "    if logger:\n",
    "        logger.info(f\"Generated embeddings for {len(test_embeddings)} test cases\")\n",
    "    \n",
    "    # Submodular function optimization with greedy algorithm\n",
    "    if logger:\n",
    "        logger.info(\"Running submodular optimization...\")\n",
    "    \n",
    "    def similarity(embedding_a, embedding_b):\n",
    "        \"\"\"Calculate cosine similarity between two embeddings\"\"\"\n",
    "        return np.dot(embedding_a, embedding_b) / (np.linalg.norm(embedding_a) * np.linalg.norm(embedding_b))\n",
    "    \n",
    "    def calculate_gain(selected_indices, candidate_index):\n",
    "        \"\"\"\n",
    "        Calculate the marginal gain of adding a new test\n",
    "        This implements a facility location objective function, which is submodular\n",
    "        \"\"\"\n",
    "        if not selected_indices:\n",
    "            # For the first selection, just use max similarity to any function\n",
    "            similarities = [similarity(test_embeddings[candidate_index], func_embedding) \n",
    "                           for func_embedding in function_embeddings]\n",
    "            return np.mean(similarities)\n",
    "        \n",
    "        # For subsequent selections, calculate marginal gain\n",
    "        gain = 0\n",
    "        for func_idx, func_embedding in enumerate(function_embeddings):\n",
    "            # Current max similarity for this function from selected tests\n",
    "            current_max = max([similarity(test_embeddings[idx], func_embedding) for idx in selected_indices])\n",
    "            # Max similarity if we add the candidate test\n",
    "            new_sim = similarity(test_embeddings[candidate_index], func_embedding)\n",
    "            # Add the marginal gain (limited to positive values)\n",
    "            gain += max(0, new_sim - current_max)\n",
    "        \n",
    "        return gain\n",
    "    \n",
    "    # Greedy selection\n",
    "    remaining_indices = set(range(len(tests)))\n",
    "    selected_indices = []\n",
    "    prioritized_tests = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while remaining_indices:\n",
    "        best_gain = -float('inf')\n",
    "        best_idx = None\n",
    "        \n",
    "        for idx in remaining_indices:\n",
    "            gain = calculate_gain(selected_indices, idx)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_idx = idx\n",
    "        \n",
    "        selected_indices.append(best_idx)\n",
    "        remaining_indices.remove(best_idx)\n",
    "        prioritized_tests.append(tests[best_idx])\n",
    "        \n",
    "        if logger and len(selected_indices) % 10 == 0:\n",
    "            logger.info(f\"Selected {len(selected_indices)}/{len(tests)} tests\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    if logger:\n",
    "        logger.info(f\"Submodular optimization complete in {end_time - start_time:.2f} seconds\")\n",
    "        logger.info(f\"First 5 selected tests:\")\n",
    "        for i, test in enumerate(prioritized_tests[:5]):\n",
    "            logger.info(f\"  {i+1}. {test['full_name']}\")\n",
    "    \n",
    "    return prioritized_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_ascii(number):\n",
    "    \"\"\"\n",
    "    Convert a number to its ASCII representation\n",
    "    \n",
    "    Args:\n",
    "        number (int): The number to convert\n",
    "    \n",
    "    Returns:\n",
    "        str: ASCII representation of the number\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert number to ASCII using chr()\n",
    "        return chr(number)\n",
    "    except ValueError:\n",
    "        return \"Invalid input. Number must be between 0 and 127.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import astunparse  # you may need to install this with pip install astunparse\n",
    "\n",
    "def display_ast(code_string):\n",
    "    \"\"\"\n",
    "    Extract and display the Abstract Syntax Tree (AST) for the given code\n",
    "    \n",
    "    Args:\n",
    "        code_string (str): The code to analyze\n",
    "    \n",
    "    Returns:\n",
    "        None: Prints AST information to console\n",
    "    \"\"\"\n",
    "    # Parse the code into an AST\n",
    "    tree = ast.parse(code_string)\n",
    "    \n",
    "    # # Print the raw AST representation\n",
    "    # print(\"Raw AST:\")\n",
    "    # print(ast.dump(tree, indent=2))\n",
    "    \n",
    "    # Print a more readable version using astunparse if available\n",
    "    try:\n",
    "        print(\"\\nAST as code:\")\n",
    "        print(astunparse.dump(tree))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Walk through the AST to display key elements\n",
    "    print(\"\\nKey elements in the AST:\")\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.FunctionDef):\n",
    "            print(f\"Function: {node.name}\")\n",
    "            print(f\"  Arguments: {[arg.arg for arg in node.args.args]}\")\n",
    "        elif isinstance(node, ast.Try):\n",
    "            print(f\"Try block with {len(node.handlers)} exception handlers\")\n",
    "        elif isinstance(node, ast.Return):\n",
    "            print(f\"Return statement at line {node.lineno}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AST as code:\n",
      "Module(\n",
      "  body=[FunctionDef(\n",
      "    name='number_to_ascii',\n",
      "    args=arguments(\n",
      "      posonlyargs=[],\n",
      "      args=[arg(\n",
      "        arg='number',\n",
      "        annotation=None,\n",
      "        type_comment=None)],\n",
      "      vararg=None,\n",
      "      kwonlyargs=[],\n",
      "      kw_defaults=[],\n",
      "      kwarg=None,\n",
      "      defaults=[]),\n",
      "    body=[\n",
      "      Expr(value=Constant(\n",
      "        value='\\n    Convert a number to its ASCII representation\\n    \\n    Args:\\n        number (int): The number to convert\\n    \\n    Returns:\\n        str: ASCII representation of the number\\n    ',\n",
      "        kind=None)),\n",
      "      Try(\n",
      "        body=[Return(value=Call(\n",
      "          func=Name(\n",
      "            id='chr',\n",
      "            ctx=Load()),\n",
      "          args=[Name(\n",
      "            id='number',\n",
      "            ctx=Load())],\n",
      "          keywords=[]))],\n",
      "        handlers=[\n",
      "          ExceptHandler(\n",
      "            type=Name(\n",
      "              id='ValueError',\n",
      "              ctx=Load()),\n",
      "            name=None,\n",
      "            body=[Return(value=Constant(\n",
      "              value='Invalid input. Number must be between 0 and 127.',\n",
      "              kind=None))]),\n",
      "          ExceptHandler(\n",
      "            type=Name(\n",
      "              id='Exception',\n",
      "              ctx=Load()),\n",
      "            name='e',\n",
      "            body=[Return(value=JoinedStr(values=[\n",
      "              Constant(\n",
      "                value='Error: ',\n",
      "                kind=None),\n",
      "              FormattedValue(\n",
      "                value=Call(\n",
      "                  func=Name(\n",
      "                    id='str',\n",
      "                    ctx=Load()),\n",
      "                  args=[Name(\n",
      "                    id='e',\n",
      "                    ctx=Load())],\n",
      "                  keywords=[]),\n",
      "                conversion=-1,\n",
      "                format_spec=None)]))])],\n",
      "        orelse=[],\n",
      "        finalbody=[])],\n",
      "    decorator_list=[],\n",
      "    returns=None,\n",
      "    type_comment=None,\n",
      "    type_params=[])],\n",
      "  type_ignores=[])\n",
      "\n",
      "Key elements in the AST:\n",
      "Function: number_to_ascii\n",
      "  Arguments: ['number']\n",
      "Try block with 2 exception handlers\n",
      "Return statement at line 13\n",
      "Return statement at line 15\n",
      "Return statement at line 17\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "# Get source code from the function\n",
    "function_source = inspect.getsource(number_to_ascii)\n",
    "display_ast(function_source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
